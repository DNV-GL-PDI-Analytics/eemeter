{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather station, zipcode, and climate zone mappings\n",
    "\n",
    "The scripts below are used to fetch, format, and process the raw data that form the mappings used by the eemeter internally.\n",
    "\n",
    "The only manually created file is the climate zone file, which was constructed from a set of references downloaded below when the top script is run; all others are primary sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "\n",
    "# ZIP code shapefiles from Census.gov\n",
    "!wget http://www2.census.gov/geo/tiger/GENZ2014/shp/cb_2014_us_zcta510_500k.zip -P data\n",
    "!unzip data/cb_2014_us_zcta510_500k.zip -d data\n",
    "!mapshaper -i data/cb_2014_us_zcta510_500k.shp -o format=geojson data/cb_2014_us_zcta510_500k.json\n",
    "\n",
    "# County shapefiles from Census.gov\n",
    "!wget http://www2.census.gov/geo/tiger/GENZ2013/cb_2013_us_county_500k.zip -P data\n",
    "!unzip data/cb_2013_us_county_500k.zip -d data\n",
    "!mapshaper -i data/cb_2013_us_county_500k.shp -o format=geojson data/cb_2013_us_county_500k.json\n",
    "\n",
    "# CA climate zone division shapefiles and transform from CEC\n",
    "!wget http://www.energy.ca.gov/maps/renewable/CA_Building_Standards_Climate_Zones.zip -P data\n",
    "!unzip data/CA_Building_Standards_Climate_Zones.zip -d data\n",
    "!ogr2ogr -f \"ESRI Shapefile\" -t_srs EPSG:4326 data/CA_Building_Standards_Climate_Zones_reprojected.shp data/CA_Building_Standards_Climate_Zones.shp\n",
    "!mapshaper -i data/CA_Building_Standards_Climate_Zones_reprojected.shp -o format=geojson data/CA_Building_Standards_Climate_Zones.json\n",
    "\n",
    "# NCDC weather data quality\n",
    "!wget ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-inventory.csv -P data\n",
    "\n",
    "# NCDC station lat lngs\n",
    "!wget ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.txt -P data\n",
    "\n",
    "# IECC/Building America climate zone csv\n",
    "!wget https://gist.githubusercontent.com/philngo/d3e251040569dba67942/raw/d1d2e13d73cc50147be6c90d8232f2e4c3eeaffc/climate_zones.csv -P data\n",
    "\n",
    "# County ids - for reference - used to derive climate_zones.csv\n",
    "!wget http://www2.census.gov/geo/docs/reference/codes/files/national_county.txt -P data\n",
    "\n",
    "# Building america climate zone guide - for reference - used to derive file below.\n",
    "!wget http://energy.gov/sites/prod/files/2015/02/f19/ba_climate_guide_2013.pdf -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import shape, Point, asShape\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathers the lat/long coordinates for all of the weather stations in the isd-history.txt file, storing them by USAF ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/isd-history.txt', 'r') as f:\n",
    "    station_lat_lng = {}\n",
    "    for row in f.readlines()[22:]:\n",
    "        try: lat = float(row[57:64])\n",
    "        except: lat = float('nan')\n",
    "\n",
    "        try: lng = float(row[65:73])\n",
    "        except: lng = float('nan')\n",
    "\n",
    "        # skip stations which are missing data\n",
    "        if pd.isnull(lat) or pd.isnull(lng): continue\n",
    "\n",
    "        station_lat_lng[row[:6]] = (lat, lng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accept only stations which have sufficient data, defined here as stations that have\n",
    "\n",
    "1. data for the past 7 years\n",
    "2. an average daily sampling rate of at least 22/day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_inventory = pd.read_csv('data/isd-inventory.csv', dtype={\"USAF\": str, \"WBAN\": str, \"YEAR\": str})\n",
    "n_years = 7\n",
    "\n",
    "def has_current_year(group):\n",
    "    # well actually, current year minus one month, just to be certain\n",
    "    # that weird things if the script runs on jan 1.\n",
    "    # give 'em time to update.\n",
    "    return group.YEAR.iloc[-1] == str((datetime.now() - timedelta(31)).year)\n",
    "\n",
    "def has_consecutive_recent_years(group):\n",
    "    consecutive = True\n",
    "    for year1,year2 in zip(group.YEAR[-n_years:], group.YEAR[-(n_years - 1):]):\n",
    "        consecutive &= (int(year1) + 1 == int(year2))\n",
    "    return consecutive\n",
    "\n",
    "def has_recent_enough_years(group):\n",
    "    return group.shape[0] >= n_years\n",
    "\n",
    "def has_rich_recent_years(group):\n",
    "    # make sure theres enough data in recent years\n",
    "    n_samples = group[[\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n",
    "                          \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"]].sum(axis=1)\n",
    "    # samples averaging at least 22 times a day for the last eight years,\n",
    "    # not counting this year, which may be incomplete.\n",
    "    return all(n_samples[-n_years:-1] > 365 * 22)\n",
    "\n",
    "station_whitelist = []\n",
    "for station, group in station_inventory.groupby(\"USAF\"):\n",
    "    # some stations have a mix of wban numbers that change the sorting\n",
    "    group = group.sort_values(by='YEAR')\n",
    "    if has_current_year(group) and \\\n",
    "            has_consecutive_recent_years(group) and \\\n",
    "            has_recent_enough_years(group) and \\\n",
    "            has_rich_recent_years(group):\n",
    "        station_whitelist.append(station)\n",
    "print(\"Accepted {} stations\".format(len(station_whitelist)))\n",
    "\n",
    "station_whitelist_lat_lng = {s: station_lat_lng[s] for s in station_whitelist}\n",
    "station_points = {s: Point(lng, lat) for s, (lat,lng) in station_whitelist_lat_lng.items()}\n",
    "station_lat_lngs = {s:(point.coords[0][1],point.coords[0][0]) for s, point in station_points.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load zipcode geojson\n",
    "with open('data/cb_2014_us_zcta510_500k.json', 'r') as f:\n",
    "    zip_js = json.load(f)\n",
    "    \n",
    "zipcode_polygons = {}\n",
    "for zip_feature in zip_js['features']:\n",
    "    zipcode = zip_feature['properties']['GEOID10']\n",
    "    polygon = shape(zip_feature['geometry'])\n",
    "    zipcode_polygons[zipcode] = polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load county geojson\n",
    "with open('data/cb_2013_us_county_500k.json', 'r') as f:\n",
    "    county_js = json.load(f)\n",
    "    \n",
    "county_polygons = {}\n",
    "for county_feature in county_js['features']:\n",
    "    county = county_feature['properties']['GEOID']\n",
    "    polygon = shape(county_feature['geometry'])\n",
    "    county_polygons[county] = polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load county climate zones:\n",
    "climate_zones = pd.read_csv('data/climate_zones.csv',\n",
    "        dtype={\"State FIPS\": str, \"County FIPS\": str},\n",
    "        usecols=[\"State FIPS\", \"County FIPS\", \"IECC Climate Zone\", \"IECC Moisture Regime\", \"BA Climate Zone\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gather a list of counties (not including california)\n",
    "counties_dict = {}\n",
    "for i, row in climate_zones.iterrows():\n",
    "    # if not in california\n",
    "    if row[\"State FIPS\"] != \"06\":\n",
    "        county_id = row[\"State FIPS\"] + row[\"County FIPS\"]\n",
    "        county_polygon = county_polygons.get(county_id)\n",
    "        if county_polygon is not None:\n",
    "            counties_dict[county_id] = {\n",
    "                \"climate_zone\": \"{}_{}_{}\".format(\n",
    "                    row[\"IECC Climate Zone\"],\n",
    "                    row[\"IECC Moisture Regime\"] if not pd.isnull( row[\"IECC Moisture Regime\"]) else \"NA\",\n",
    "                    row[\"BA Climate Zone\"]),\n",
    "                \"polygon\": county_polygon,\n",
    "            }\n",
    "        else:\n",
    "            print(\"Could not find county {}, skipping.\".format(county_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load CA climate zones:\n",
    "with open('data/CA_Building_Standards_Climate_Zones.json', 'r') as f:\n",
    "    ca_js = json.load(f)\n",
    "\n",
    "california_climate_zone_polygons = {}\n",
    "for ca_feature in ca_js['features']:\n",
    "    zone = \"CA_{:02d}\".format(int(ca_feature['properties']['Zone']))\n",
    "    polygon = shape(ca_feature['geometry'])\n",
    "    california_climate_zone_polygons[zone] = polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map zipcodes to climate zones\n",
    "\n",
    "# outputs - may as well store the zipcode centroids for later use.\n",
    "zipcode_to_climate_zone = {}\n",
    "zipcode_points = {}\n",
    "zipcode_centroids = {}\n",
    "\n",
    "# some optimizations for the loop.\n",
    "counties_dict_items = counties_dict.items()\n",
    "california_climate_zone_polygons_items = california_climate_zone_polygons.items()\n",
    "n_zipcodes = len(zipcode_polygons)\n",
    "\n",
    "for i, (zipcode, zipcode_poly) in enumerate(zipcode_polygons.items()):\n",
    "    print '\\r{} of {}'.format(i+1, n_zipcodes),\n",
    "    \n",
    "    # note that centroids are not always within the zipcode, or even necessarily on land (or within the county they are contained by)! This is a rough approximation of location.\n",
    "    zipcode_centroid = zipcode_poly.centroid\n",
    "    zipcode_points[zipcode] = zipcode_centroid\n",
    "    zipcode_centroids[zipcode] = (zipcode_centroid.coords[0][1], zipcode_centroid.coords[0][0])\n",
    "    \n",
    "    # check non-CA counties\n",
    "    for county, county_dict in counties_dict_items:\n",
    "        county_poly = county_dict[\"polygon\"]\n",
    "        if county_poly.contains(zipcode_centroid):\n",
    "            zipcode_to_climate_zone[zipcode] = county_dict[\"climate_zone\"]\n",
    "            break\n",
    "    else: #for else!\n",
    "        # check CA climate zones\n",
    "        for ca_cz, ca_cz_poly in california_climate_zone_polygons_items:\n",
    "            if ca_cz_poly.contains(zipcode_centroid):\n",
    "                zipcode_to_climate_zone[zipcode] = ca_cz\n",
    "                break\n",
    "        else: #for else!\n",
    "            zipcode_to_climate_zone[zipcode] = None      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# map weather stations to climate zones\n",
    "\n",
    "station_to_climate_zone = {}\n",
    "\n",
    "n_stations = len(station_points)\n",
    "\n",
    "for i, (station, station_point) in enumerate(station_points.items()):\n",
    "    print '\\r{} of {}'.format(i+1, n_stations),\n",
    "    \n",
    "    # Is the station in a non-CA county?\n",
    "    for county, county_dict in counties_dict_items:\n",
    "        county_poly = county_dict[\"polygon\"]\n",
    "        if county_poly.contains(station_point):\n",
    "            station_to_climate_zone[station] = county_dict[\"climate_zone\"]\n",
    "            break\n",
    "    else: #for else!\n",
    "        \n",
    "        # is the station in a california climate zone?\n",
    "        for ca_cz, ca_cz_poly in california_climate_zone_polygons_items:\n",
    "            if ca_cz_poly.contains(station_point):\n",
    "                station_to_climate_zone[station] = ca_cz\n",
    "                break\n",
    "        else: #for else!\n",
    "            station_to_climate_zone[station] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map stations to zipcodes by looking, if possible, for the closest weather station within\n",
    "the same climate zone. If not within a climate zone, just pick the station which is\n",
    "overall closest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zipcode to station mapping\n",
    "zipcode_to_station = {}\n",
    "all_stations = station_points.keys()\n",
    "for i, (zipcode, zipcode_point) in enumerate(zipcode_points.items()):\n",
    "    print(\"\\r{} of {}\".format(i + 1, n_zipcodes)),\n",
    "    \n",
    "    # get set of stations to compare for distance.\n",
    "    climate_zone = zipcode_to_climate_zone[zipcode]\n",
    "    if climate_zone is None:\n",
    "        stations = all_stations\n",
    "    else:\n",
    "        stations = climate_zone_to_stations[climate_zone]\n",
    "    \n",
    "    # find minimum distance\n",
    "    min_dist = 1e16\n",
    "    min_station = None\n",
    "    for station in stations:\n",
    "        dist = zipcode_point.distance(station_points[station])\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_station = station\n",
    "    zipcode_to_station[zipcode] = min_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some other JSON products that may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# climate zone to zipcode list mapping\n",
    "climate_zone_zipcodes = defaultdict(list)\n",
    "for zipcode, climate_zone in zipcode_to_climate_zone.items():\n",
    "    if climate_zone is not None:\n",
    "        climate_zone_zipcodes[climate_zone].append(zipcode)\n",
    "climate_zone_to_zipcodes = dict(climate_zone_zipcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# climate zone to station list mapping\n",
    "climate_zone_to_stations = defaultdict(list)\n",
    "for station, climate_zone in station_to_climate_zone.items():\n",
    "    if climate_zone is not None:\n",
    "        climate_zone_to_stations[climate_zone].append(station)\n",
    "climate_zone_to_stations = dict(climate_zone_to_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# station to zipcode list mapping\n",
    "station_to_zipcodes = defaultdict(list)\n",
    "for zipcode, station in zipcode_to_station.items():\n",
    "    if station is not None:\n",
    "        station_to_zipcodes[station].append(zipcode)\n",
    "station_to_zipcodes = dict(station_to_zipcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# station to climate zone mapping\n",
    "station_to_climate_zone = {}\n",
    "for climate_zone, stations in climate_zone_to_stations.items():\n",
    "    for station in stations:\n",
    "        station_to_climate_zone[station] = climate_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write all outputs:\n",
    "!mkdir -p outputs\n",
    "\n",
    "\n",
    "### Station -> X\n",
    "# station -> lat long\n",
    "with open('outputs/usaf_station_lat_long.json', 'w') as f:\n",
    "    json.dump(station_lat_lngs, f)\n",
    "\n",
    "# station -> zipcodes\n",
    "with open('outputs/usaf_station_zipcodes.json', 'w') as f:\n",
    "    json.dump(station_to_zipcodes, f)\n",
    "\n",
    "# station -> climate_zone\n",
    "with open('outputs/usaf_station_climate_zone.json', 'w') as f:\n",
    "    json.dump(station_to_climate_zone, f)\n",
    "\n",
    "\n",
    "### Zipcode -> X\n",
    "# zipcode -> lat long\n",
    "with open('outputs/zipcode_centroid_lat_long.json', 'w') as f:\n",
    "    json.dump(zipcode_centroids, f)\n",
    "    \n",
    "# zipcode -> climate_zone\n",
    "with open('outputs/zipcode_climate_zone.json', 'w') as f:\n",
    "    json.dump(zipcode_to_climate_zone, f)\n",
    "\n",
    "# zipcode -> station\n",
    "with open('outputs/zipcode_usaf_station.json', 'w') as f:\n",
    "    json.dump(zipcode_to_station, f)\n",
    "    \n",
    "\n",
    "### climate zone -> X\n",
    "# climate_zone -> stations\n",
    "with open('outputs/climate_zone_usaf_stations.json', 'w') as f:\n",
    "    json.dump(climate_zone_to_stations, f)\n",
    "\n",
    "# climate_zone -> zipcodes\n",
    "with open('outputs/climate_zone_zipcodes.json', 'w') as f:\n",
    "    json.dump(climate_zone_to_zipcodes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
